{
    "collab_server" : "",
    "contents" : "#Reading dataset\ndataset <- read.csv(\"kc_house_data.csv\")\nhouseData <- subset(dataset, select = c(\"price\",\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",\"condition\",\"grade\",\"sqft_above\",\"sqft_basement\",\"yr_built\",\"yr_renovated\",\"zipcode\",\"lat\",\"long\",\"sqft_living15\",\"sqft_lot15\"))\n\n# Point number 1\nsummary(houseData$price)\nsd(houseData$price)\n\n# Point number 2\n# Partitioning dataset in 80% training data and 20% testing data.\n# 80% of the sample size\nsmp_size <- floor(0.80 * nrow(houseData))\n\n## set the seed to make your partition reproductible\nset.seed(20161101)\ntrain_sample <- sample(seq_len(nrow(houseData)), size = smp_size)\n\n#Obtaining training and test portions from house data\nhouse.Train <- houseData[train_sample, ]\nhouse.Test <- houseData[-train_sample, ]\n\n# 2.a cases in training data set\nnrow(house.Train)\n# 2.b cases in test data set\nnrow(house.Test)\n\n# 2.c\n  # Summary for Training set\nsummary(house.Train$price)\nsd(house.Train$price)\n  # Summary for Test set\nsummary(house.Test$price)\nsd(house.Test$price)\n\n# 2.d\n  # Fitting a multiple linear regression model\nhPrice.Tr.lm <- lm(price~., data=house.Train)\nsummary(hPrice.Tr.lm)\n#anova(house.Train.lm)\n\n# 2.e\n  # Use the automatic forward/backward selection method to derive the \\best\" model\nhPrice.null <- lm(price~ 1, data=house.Train) \nhousing.best <- stepAIC(hPrice.null, scope=list(upper=hPrice.Tr.lm,lower=hPrice.null),direction=\"both\")\nsummary(housing.best)\n\n# 2.f\n  # Draw scatterplots of the residuals in the \\best\" model against each of the predictors.\npar(mfrow=c(3,3))\ncrPlots(housing.best, line = TRUE, smooth = TRUE)\n\n# 2.g\n#---------------------------------------------------\n# Selected predictors with non-linear effects\n# sqft_living, bathrooms, sqft_above\n#---------------------------------------------------\n\n#Calculate time for CV task to put a delay and wait for this task to complete (in nested for loops). \nstart.time <- Sys.time()\nlm.Highest.Ply <- lm(price ~. - floors - sqft_basement + poly(sqft_living, 5) + poly(bathrooms, 5) + poly(sqft_above, 5), data=houseData)\ncv.Highest.Ply <- cv.lm(houseData, lm.Highest.Ply, m = 5, plotit = FALSE)\nMSE.p <- attr(cv.Highest.Ply, \"ms\")\nend.time <- Sys.time()\ntaken.time <- (end.time - start.time) %>% round()\n#taken.time\n#vector to save the MSE of each CV for each Polynomial\nMSE.Ply <- rep(0, 125)\nfolds <- 5\n\n#---------------------------------------------------\n# For loop to perform iteratively cross validation and linear models with polynomials for \n# \"sqft_living\",\"bathrooms\" and \"sqft_above\".\n\nfor(i in 1:5){\n  for(j in 1:5){\n    for(k in 1:5){\n      #Linear model for all the polynomials of \"sqft_living\", \"bathrooms\", \"sqft_above\" \n      lm.Poly <- lm(price ~. - floors - sqft_basement + poly(sqft_living, i) + poly(bathrooms, j) + poly(sqft_above, k), data=houseData)\n      cv.Poly <- cv.lm(houseData, lm.Poly, m = folds, plotit = FALSE)\n      #Save MSE of each polynomial for the three selected predictors for ploting (in order)\n      MSE.Ply[((i-1)*25) + ((j-1)*5) + k] <- attr(cv.Poly,\"ms\")\n      #Delay in system to allow R finishing cross validation before continuing with the next\n      Sys.sleep(taken.time)\n    }\n  }\n}\n\n#Obtain index of minimum MSE\nwhich.min(MSE.Ply)\n\n#Get MSE of the CV with the minimum value\nMSE.min <- MSE.Ply[which.min(MSE.Ply)]\n\n#Print Cross-Validation results of the polynomial with the minimum MSE\nlm.min.MSE <- lm(price ~. - floors - sqft_basement + poly(sqft_living, 2) + poly(bathrooms, 2) + poly(sqft_above, 1), data=houseData)\ncv.min.MSE <- cv.lm(houseData, lm.Highest.Ply, m = 5, plotit = FALSE)\n\n#Vector with MSEs of each fold for the minimum MSE of the polynomials\nMSEk.31 <- c(4.27e+10, 3.8e+10, 3.41e+10, 3.93e+10, 3.27e+10)\n\n#Calculating standard error \nSE.MSEk.31 <- sd(MSEk.31)/sqrt(folds)\nSE.MSEk.31\n#Plot of the MSE for all crossvalidations\nPoly.list <- (1:125)\npar(mfrow=c(1,1))\nplot(Poly.list,MSE.Ply, type = \"o\", col = \"chocolate1\", lwd = 2, main = \"5-fold CV for all possible polynomials\", xlab = \"Number of Polynomial\", ylab = \"Mean Squared Error\")\nabline(as.numeric(MSE.min + SE.MSEk.31), b = 0,col = \"red\", lwd = 2)\n",
    "created" : 1494494803369.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3616682070",
    "id" : "DAF8D149",
    "lastKnownWriteTime" : 1478991591,
    "last_content_update" : 1478991591,
    "path" : "~/JACOBS/Primer semestre/Principles of Statistical Modeling/Miniquiz-3/PSM_MQ_3/MQ3 - 2.R",
    "project_path" : "MQ3 - 2.R",
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}